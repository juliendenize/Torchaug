{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaug.transforms._color import RandomGrayscale, BatchRandomGrayscale, BatchGrayscale, BatchRandomColorJitter,  BatchColorJitter\n",
    "\n",
    "transform = RandomGrayscale(1)\n",
    "batch_transform = BatchRandomColorJitter(0., 0., 0., 0.1, 0.5)\n",
    "batch_transform_2 = BatchColorJitter(0., 0., 0., 0.1, num_chunks=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "img = torch.randint(0, 256, (3, 256, 256), dtype=torch.uint8, device=\"cpu\")\n",
    "batch_img = torch.stack([img, img + 10, img], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = transform(img)\n",
    "batch_gray_img = batch_transform(batch_img)\n",
    "batch_gray_img_2 = batch_transform_2(batch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(145, dtype=torch.uint8),\n",
       " tensor(12, dtype=torch.uint8),\n",
       " tensor(12, dtype=torch.uint8),\n",
       " tensor(12, dtype=torch.uint8),\n",
       " tensor(58, dtype=torch.uint8),\n",
       " tensor(12, dtype=torch.uint8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[0, 0, 0], img[0, 0, 0], batch_img[0, 0, 0, 0], batch_gray_img[0, 0, 0, 0], batch_gray_img[1, 0, 0, 0], batch_gray_img[2, 0, 0, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_img_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([231, 143, 227, 119, 116, 127, 111,  59, 102, 194, 153, 159,  29, 170,\n",
       "         234,  51, 190, 213, 132,  82,  49, 190,  83, 193, 155, 119, 208,  74,\n",
       "          68,  44,  61,  87, 109, 222, 160,  41, 213, 201, 236, 124,   0, 220,\n",
       "          77, 165,   6, 223,  35, 193,  98, 118, 211,  82, 222, 247,  84, 167,\n",
       "         173, 112, 219, 212,  34, 252, 184, 219,   3, 115,  33, 146, 224, 200,\n",
       "          30,  52,   5, 152, 208, 134, 106,  78,  16, 234, 214, 210, 108,  29,\n",
       "          56,  75,  10, 221, 192,  53, 160,  60,  38, 167, 188, 234, 166, 131,\n",
       "         140, 248,  78,   5, 156,  24, 198, 140,   2, 135, 194, 199,  75, 180,\n",
       "          85, 111,  53,  85,  69, 141, 142,  53, 171, 164,  72,  90, 187, 247,\n",
       "         236,  67,  24,  90,  58, 227, 209,  22, 102,  34, 203, 251,  52, 198,\n",
       "          41, 125, 206, 166, 195, 113, 252,   3, 175, 143, 243, 219, 175, 189,\n",
       "         156, 144, 134, 254, 173,  17, 146,  56, 131, 107, 125, 235, 150, 198,\n",
       "           2, 217, 108, 211,   7, 224, 125,  98,  32, 101,  35, 117, 126, 137,\n",
       "         173, 105,   7, 217,  15, 162, 241,   4, 179, 149,  28,  89, 124, 116,\n",
       "         226,  51,  33, 213, 132, 180, 151, 183, 232, 133, 133,  29, 245, 235,\n",
       "          92, 127, 143, 182, 181, 240, 151,   4,  76,  74, 121,   2, 236, 150,\n",
       "         155, 184,  41, 181, 253,  30,  29,  28, 246,   1, 123, 114,  27, 218,\n",
       "          82, 151,  68,  51, 234,  58,  50, 116,  12, 116,   1, 188, 215, 100,\n",
       "          38,  39, 141,  60], dtype=torch.uint8),\n",
       " tensor([241, 111, 237, 155, 125, 128, 120,  51,  94, 204, 143, 168,  39, 154,\n",
       "         244,  73, 148, 223, 141,  44,  77, 200, 135, 181, 164, 128, 218, 106,\n",
       "          89,  85,  63, 108, 140, 232, 204,  89, 194, 182, 246, 171,  10, 215,\n",
       "          34, 151,  16, 233,  45, 203, 140, 103, 221,  87, 232,   1,  94, 215,\n",
       "         172,  96, 209, 209,  44,   6, 215, 229,   5, 117,  43, 179, 234, 210,\n",
       "          40,  62,  15, 151, 218, 143, 115,  45,  26, 244, 224, 217, 117,  39,\n",
       "          66,  85,  20, 231, 202,  63, 169,  57,  98, 176, 216, 244, 133, 151,\n",
       "         106,   2,  88,  15, 165,  34, 208, 165,  12, 127, 204, 209,  65, 190,\n",
       "          95,  80,  63,  51,  94, 150,  94,  62, 181, 155,  82, 139, 197,   1,\n",
       "         246, 110,  34, 100,  75, 237, 219,  32, 111,  44, 213,   5,  62, 212,\n",
       "          48, 134, 208, 163, 205, 122,   6,  13, 163, 169, 253, 229, 212, 199,\n",
       "         175, 153, 143,   8, 193,   9, 121,  66, 114, 112, 134, 245, 159, 215,\n",
       "          16, 227, 117, 221,   9, 228, 113,  77,  42, 128,  45, 126, 160, 146,\n",
       "         162, 114,  17, 227,  25, 171, 251,  14, 148, 173,  38,  98, 133, 125,\n",
       "         236,  76,  89, 223, 141, 190, 139, 193, 242, 142, 172,  39, 255, 245,\n",
       "          95, 152, 151, 205, 148, 250, 135,  14, 133,  84, 130,  12, 201, 149,\n",
       "         173, 227, 100, 207,   7,  92,  39,  22,   0,  11, 157, 123,  37, 228,\n",
       "          92, 188,  78,  61, 244,  68,  60, 140,  22, 152,  11, 198, 225, 109,\n",
       "          41,  49, 150,  70], dtype=torch.uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms.v2 import RandomEqualize\n",
    "\n",
    "equalize = RandomEqualize(1.0)\n",
    "\n",
    "equalize(img)[1, 0], equalize(batch_img)[1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
